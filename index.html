<!DOCTYPE html>
<html>

<head>
  <title>Corentin Dumery</title>
  <link rel="stylesheet" href="style.css" />
  <link rel="icon" href="images/favicon.png">
  <meta property="og:type" content="website">
  <meta property="og:image" content="images/flower.png" />
  <meta property="og:description" content="Personal website and portfolio" />
  <meta property="og:title" content="Corentin Dumery" />

  <meta property="twitter:card" content="summary">
  <meta property="twitter:title" content="Corentin Dumery">
  <meta property="twitter:description" content="Personal website and portfolio">
  <meta property="twitter:image" content="images/flower.png">

</head>


<header>
  <img id="header_background" src="images/delaunay.png"/>
</header>

<body>

  <menubar>
    <a href="index.html" class="current_menubar"><moving>Corentin Dumery</moving></a>
    <submenubar>
      <a href="#evocube_article"> <moving> Evocube </moving></a>
      <a href="#pattern_article"> <moving> Pattern Making </moving></a>
      <a href="#bmesh_article"> <moving> B-Mesh Modeller </moving></a>
      <a href="#aesthetic_article"> <moving> Aesthetic functions </moving></a>
      <a href="#cow_article"> <moving> Cow texture generator </moving></a>
      <!--<a href="#transformation_article"> <moving> 3D Mesh Segmentation </moving></a>
      <a href="#skull_article"> <moving> Skull implants </moving></a>
      <a href="#potato_article"> <moving> Potato generator </moving></a>
      <a href="#tipe_article"> <moving> Crop/Area allocation </moving></a>-->
    </submenubar>
    <a href="about/resume.html"> <moving> Resume  </moving> </a>
    <a href="about/gallery.html"> <moving> Gallery </moving> </a>
    <a href="about/blog.html"> <moving> Blog </moving></a>
  </menubar>

  <article height="100%">
    <div id="namecard">
      <div>
        <h1> Corentin Dumery </h1>
        <h3> PhD student
        at&nbsp;
        <img src="images/epfl-black.png" height="16em" alt=" EPFL"/><br>
        
        <a href="https://www.epfl.ch/labs/cvlab/">CVLab</a>
        </h3>
        <h4> Contact: <br> first name dot last name at epfl dot ch </h4>

      </div>
      <div><img id="circle_cv" src="images/circle_cv_photo.PNG" width="100%"></div>
    </div>
    <div>
      <p>
        My research interests lie at the intersection of computer vision and computer graphics. 
        I am dedicated to advancing machine perception through 3D scene reconstruction and understanding, enabling machines to not
        only see their environment but also comprehend and interact with it. My work also emphasizes 3D content creation for digital
        AR/VR environments, leveraging both real-world reconstruction and AI-assisted 3D generation.</br> 
      </p>
      I graduated from <a href="https://www.nus.edu.sg">NUS</a> and
      <a href="https://www.telecom-paris.fr/en/home">Télécom Paris</a> in 2020.
      After graduation, I worked at
      <a href="https://www.cea.fr/english/Pages/cea/the-cea-a-key-player-in-technological-research.aspx">CEA Paris-Saclay</a>
      on polycube mapping, and later joined <a href="https://igl.ethz.ch/people/sorkine/index.php">Prof. Olga Sorkine-Hornung</a>'s
      lab at ETH Zürich as a visiting researcher on garment fabrication.
      <br/>
      <!--
      <p>
        My primary research interests are in 3D geometry processing and its applications,
        which range from physics-based simulation to animation.
        In the past, I have worked on a number of topics related to discrete shape modeling,
        such as mesh deformation, hexahedral meshing, differentiable rendering,
        or semantic mesh segmentation. I'm also interested in data science techniques and how they
        can be applied to 3D problems, such as machine learning & optimization, operations research,
        extended Kalman filtering, and dimensionality reduction.
      </p>
      -->
      <p>
      For those who are unsure, <a href="sound/corentindumery.mp3">here</a>'s how my name is pronounced in French.
      </p>

      
      <p>
        <span>&#10230;</span> Students interested in a <b>semester project or master thesis</b>, please consult our lab's <a href="https://www.epfl.ch/labs/cvlab/projects/">project page</a>.</br>
        <span>&#10230;</span> Master/Bachelor <b>summer interns</b>, please apply to the <a href="https://summer.epfl.ch/">Summer@EPFL</a> program.</br>
        <span>&#10230;</span> <b>PhD applicants</b>, please refer to the <a href="https://www.epfl.ch/education/phd/edic-computer-and-communication-sciences/">doctoral program page</a> or our 
        <a href="https://epic-guide.github.io/">student-wiki</a>.</br>
      </p>
      If you would like to contact me, please make it clear you have had a look at these resourses and avoid sending a generic email.
    </div>

    <iconbar>
      <a href="https://github.com/CorentinDumery/"><img class="icon" src="images/github.png"></a>
      <a href="https://www.youtube.com/channel/UCEiDor6J3-FmC9I1Sv-AKtQ"><img class="icon" src="images/youtube.png"></a>
      <a href="https://www.linkedin.com/in/corentin-dumery-2754281a0/"><img class="icon" src="images/linkedin.png"></a>
      <a href="https://scholar.google.com/citations?hl=fr&user=lUXqyiMAAAAJ"><img class="icon" src="images/scholar.png"></a>
    </iconbar>

  </article>

  <article>
    <div class="article_text" id="disconerf_article">
      <p> 
        <h1>Enforcing View-Consistency in Class-Agnostic 3D Segmentation Fields 
          [<a href="projects/disconerf.html">CVPRW 2025</a>]</h1>
      <riddle>
        How to produce a consistent 3D radiance field segmentation from a set of inconsistent 2D masks?<br>
      </riddle>

      Given as input a set of class-agnostic 2D masks generated by a foundation model, we aim to
      <b>learn a meaningful 3D object field</b> that segments the different instances in the scene. However, 
      these masks tend to have <b>little consistency</b> across views, making this task challenging.
      </br>
      We propose to <b>match the 2D masks with the channels of a rendered object field</b>, and introduce
      a <b>3D spatial-consistency regularizer</b>. This allows us to produce consistent 3D segmentations,
      which can then be used to extract 3D assets for AR/VR or other digital environments.
      <ul>
        <li><a href="projects/disconerf.html"> Project page </a>
          <li><a href="https://arxiv.org/abs/2408.09928"> Paper </a>
        <li><a href="https://opensun3d.github.io/">Workshop website</a></li>
        <li><a href="https://drive.google.com/file/d/1qq8o9axqqxhiVmdxQxuH8GpawV0Bel7Y/view?usp=sharing">Ground-Truth Mip-NeRF360 Segmentations</a></li>
      </ul>

      <br><br>
      <img id="evocube_teaser" src="images/disconerf.png" align="middle" width="100%">
      <br>
    </div>
  </article>

  <article>
    <div class="article_text" id="garment_recon_article">
      <p> 
        <h1>3D Garment Reconstruction 
          [<a href="https://liren2515.github.io/page/prior/prior.html">CVPR24</a>, <a href="https://liren2515.github.io/page/folding/folding.html">NeurIPS24</a> , <a href="https://liren2515.github.io/page/dmap/dmap.html">SIGGRAPH25</a>]</h1>

          
      <riddle>
        From a single 2D image or from a partial point cloud, how can we recover a full 3D garment? <br>
      </riddle>

      Recovering a full 3D model of a garment from just a single image, 
      especially when it's being worn or handled, can be a complex task due to partial visibility.
      To achieve this, we leverage garment-specific geometric priors 
      to accurately reconstruct the visible parts of garments 
      while inferring the unseen areas to recover a complete and realistic 3D model.

      <ul>
        <li><a href="https://liren2515.github.io/page/prior/prior.html">Garment Recovery with Shape and Deformation Priors</a></li>
        <li><a href="https://liren2515.github.io/page/folding/folding.html">Reconstruction of Manipulated Garment with Guided Deformation Prior</a></li>
        <li><a href="https://liren2515.github.io/page/dmap/dmap.html">Single View Garment Reconstruction Using Diffusion Mapping Via Pattern Coordinates</a></li>
       </ul>

      <br>
      <video autoplay muted loop width="70%" class="centered_pic">
        <source src="images/CVPR24.mp4" type="video/mp4" >
        Your browser does not support the video tag.
      </video>
      </p>
    </div>
  </article>

  <article>
    <div class="article_text" id="evocube_article">
      <p>
      <a href="projects/evocube.html"><h1>Evocube [CGF22]</h1></a>
      <riddle> <!-- Let's assume  our reader has a very short attention span -->
        Given an input 3D shape, how can we deform it into a similar
        <b>polycube</b>? <br>
        → check out the <a href="projects/evocube.html"> Project page</a>.
      </riddle>


      Polycubes, i.e. aggregates of axis-aligned cubes, are most notably used for all-hex meshing, but
      their constrained nature and topology conditions make polycube parameterization
      a challenging task.
      Previous work
      has shown the feasibility of precomputing polycube orientation directly on the input mesh,
      effectively <b>labeling</b> each boundary face in blue/white/red representing the XYZ axes.
      </br>
      How can we derive a fitting polycube topology from a triangle mesh? We propose the use of a
      novel <b>genetic algorithm</b> in the context of polycube labeling optimization, defining fitness,
      crossover, and mutations.
      </br>



      <img id="evocube_teaser" src="images/teaser_evocube_simple.png" align="middle" width="100%">
      <br>
      </p>
    </div>
  </article>



  <article>
    <div class="article_text" id="pattern_article">
      <p>
      <h1><a href="https://igl.ethz.ch/projects/computational-patternmaking/">Computational Pattern Making [SIGGRAPH22]</a></h1>
      <riddle>
      Given a <b>3D garment</b>,
      how can we generate a <b>2D sewing pattern</b> that can effectively be used to manufacture it?
      </riddle>
      Our algorithm segments an input 3D shape into patches
      and computes their 2D parameterization, while accounting for <b>the unique
      properties and constraints of tailoring</b>, such as seam symmetry,
      darts, fabric grain alignment, and a flattening distortion measure that models
      woven fabric deformation, respecting its anisotropic behavior.
      <!--We bootstrap
      a recent patch layout approach developed for quadrilateral remeshing and
      adapt it to the purpose of computational pattern making.-->
      </br>

      <ul>
       <li><a href="projects/computational-pattern-making-compressed.pdf"> Paper (2 Mb)</a>, <a href="https://igl.ethz.ch/projects/computational-patternmaking/computational-pattern-making-paper.pdf"> high resolution (38 Mb)</a></li>
       <li><a href="https://www.youtube.com/watch?v=wsrQiH3zyuI">15mn presentation</a></li>
       <!-- <a href="https://arxiv.org/abs/2202.10272"> arXiv </a> --->
       <li>Our code is open source: <a href="https://github.com/CorentinDumery/garment-flattening">anisotropic textile parameterization</a>
          + <a href="https://github.com/nicopietroni/parafashion">patch segmentation (main project)</a></li>
       <li><a href="https://www.youtube.com/watch?v=7b27T8rh7SU">Supplemental video</a></li>
       <li><a href="https://igl.ethz.ch/publications/igl-bibtex.php#ComputationalPatternmaking:2022">bibtex</a></li>
      </ul>
      <img id="parafashion_teaser" src="images/parafashion_teaser.jpg" align="middle" width="100%">
      <br>
      </p>
    </div>
  </article>

  <article>
    <div class="article_text" id="bmesh_article">
      <p>
      <h1>B-Mesh Modeller</h1>
      With two friends from Télécom Paris, we created a 3D modelling software based on a novel approach described in <a
        href="https://pdfs.semanticscholar.org/2009/3aea25b50e59c63998ba0377371c59bf007f.pdf">a research paper</a>.
      The idea is to create an initial mesh in only a few minutes by placing spheres in 3D to represent
      the skeleton of the modelled object. The user can freely create and customize the mesh. It can be
      modified in real-time.
      (<a href="https://github.com/CorentinDumery/Bmesh">link to the project</a></li>) <br /> <br />

      <img id="bmesh_ex" src="images/bmesh_example.PNG" align="middle" width="100%">
      <br><br><br>
      <div class="video_container">
        <iframe class="video" src="https://www.youtube.com/embed/_TSeF4pfgXs" frameborder="0" allowfullscreen></iframe>
      </div>
      </p>
    </div>
  </article>

  <article>
    <div class="article_text" id="aesthetic_article">
      <p>
      <h1>Aesthetic functions</h1>
      This is a fun little project to explore the artistic side of two-dimensional functions. All you have to do is
      enter a
      math function and play with the sliders to generate some stunning artworks.
      Any function works, no matter how complex, but even on simpler ones the results are often surprising.
      If you do try it out, please send me your creations!
      (<a href="https://github.com/CorentinDumery/aesthetic-functions">link to the project</a></li>) <br /> <br />

      <table>
        <tr align="middle" >
          <td width="50%"><img id="color_ex0" src="images/aesthetic/blackhole.png" align="middle" width="95%"></td>
          <td width="50%"><img id="color_ex1" src="images/aesthetic/sea_floor.png" align="middle" width="95%"></td>
        </tr>
        <tr>
          <th>Black hole of odd dimension</th>
          <th>Sea floor</th>
        </tr>
        <tr align="middle">
          <td width="50%"><img id="color_ex1" src="images/aesthetic/color_dance.png" align="middle" width="95%"></td>
          <td width="50%"><img id="color_ex0" src="images/aesthetic/miracle_of_life.png" align="middle" width="95%"></td>
        </tr>
        <tr>
          <th>Color dance</th>
          <th>Miracle of Life</th>
        </tr>
      </table>

      <br><br>

      And some of them move, too! There's plenty more
      <a href="https://github.com/CorentinDumery/aesthetic-functions">where these come from</a>,
      <a href="about/blog/aestheticfunctions.html"> some moving here</a>,
      <a href="about/blog/aliasing.html">some surprising there</a>,
      and they all have something that all the others don't have.
      I always love receiving creations from other people, so feel free to send me an email
      if you find inspiration!
      <br>

      </p>
    </div>
  </article>


  <article>
    <div class="article_text" id="cow_article">
      <p>
      <h1>Cow Texture generator</h1>
      Ever felt the need to have an infinite supply of cow pattern textures? <br /><br />

      This project was inspired by <a href="https://mgmalheiros.github.io/research/leopard/"><i>The leopard never
          changes
          its spots</i></a>, a SIGGRAPH 2020 paper by Malheiros, Marcelo de G. and Fensterseifer, Henrique and Walter,
      Marcelo. This paper uses a reaction-diffusion model to approximate
      tissue growth, and successfully generates a few 2D patterns matching real species. This project aims to adapt
      this model to generate cow patterns, which were not covered in the original article.
      (<a href="https://github.com/CorentinDumery/cow-tex-generator">link to the project</a></li>) <br/> <br />

      <img class="centered_pic" src="images/textures_pres.png" width="100%">
      <br/>
      <video autoplay muted loop width="100%" class="centered_pic">
        <source src="images/cowanim.mp4" type="video/mp4" >
        Your browser does not support the video tag.
      </video>
      
      </p>
    </div>
  </article>

  <article>
    <div class="article_text"  id="transformation_article">
      <p>
      <h1>Evaluation of a Spectral Data Transformation Method for Meaningful Mesh Segmentation</h1>
      I wanted to see if I could transform a 3D mesh in a weaningful way to make 3D segmentation easier.
      To evaluate this transformation, I used
      <a href="https://segeval.cs.princeton.edu/">this awesome dataset</a></li> which includes human-generated ground
      truth segmentations,
      and used simple clustering algorithms to generate a segmentation. By comparing results with the ground truth, I
      was able to measure the
      efficiency of this approach and identify the circumstances under which it's useful. For more detail, here is
      <a
        href="https://github.com/CorentinDumery/3DTransformation/blob/master/Evaluation%20of%20a%20Spectral%20Data%20Transformation%20Method%20for%20Meaningful%20Mesh%20Segmentation.pdf">a
        link to the complete study</a></li>.
      You can also take a look at
      <a href="https://github.com/CorentinDumery/3DTransformation">the project on github</a></li>. <br /> <br />
      <img id="glassesSeg" src="images/glassesCl.png" align="middle" width="100%">
      </p>
    </div>
  </article>

  <article>
    <div class="article_text" id="skull_article">
      <p>
      <h1>Design of Implants for Skull Reconstructive Surgery</h1>
      This project aims to make 3D skull implant generation as easy as possible. The idea is to input a mesh derived
      from a CT scan and use two edge loops
      to specify the part of the skull where an implant should be generated. The skull layer is then reconstructed to
      make a perfect-fit implant. Then, a
      flattening algorithm is used to flatten each layer of the implant to make it suitable for implant 3D printing.
      Cutting path are added to release some
      flattening constraints. This work was done for the National University of
      Singapore in collaboration with
      <a href="https://www.osteopore.com/">Osteopore</a></li>,
      and uses a patented software from NUS to reconstruct the outer layer of the skull using symmetry constraints.
      <br /> <br />
      <img id="defectS" class="centered_pic" src="images/defectSkull.png" width="80%">
      <img id="implant" class="centered_pic" src="images/implant.png" width="80%">
      </p>
    </div>
  </article>

  <article>
    <div class="article_text" id="potato_article">
      <p>
      <h1>Potato Generator</h1>
      Simple project that generates a 3D potatoïd based on input parameters. Perturbations with a given frequency,
      amplitude and
      direction are applied to a sphere to create the illusion of a natural object.
      (<a href="https://github.com/CorentinDumery/potato-generator">link to the project</a></li>) <br /> <br />
      <video autoplay muted loop width="40%" class="centered_pic">
        <source src="images/potato.mp4" type="video/mp4" >
        Your browser does not support the video tag.
      </video>
      </p>
    </div>
  </article>

  <article>
    <div class="article_text" id="tipe_article">
      <p>
      <h1>[FRENCH] Modélisation agricole et optimisation de la répartition des surfaces</h1>
      Here's a video I made when I was 19 showing the different steps in my research trying to optimize the area
      allocation of an agricultural exploitation. It's in French and quite simple since this was done very early during
      my studies, but if you have any questions I'd be more than willing to speak about it with you. It was a fun
      experience and I enjoyed the freedom that I was given on this project.<br /> <br />

      <div class="video_container">
      <iframe class="video" width="560" height="315" src="https://www.youtube.com/embed/YgApnVLuq7c" frameborder="0"
        allowfullscreen></iframe>
      </div>
      </p>
    </div>
  </article>


  <article>
    <div class="article_text">
      <p>
      <h1>More information</h1>
      For more information, feel free to contact me at corentin.dumery at gmail.com.
      You can also download my resume <a href="CV_DUMERY.pdf" download>here</a>.
      </p>
    </div>
  </article>
</body>
</html>
