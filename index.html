<!DOCTYPE HTML>
<html lang="en">
    <div class="header-background">
    <img id="header_background" src="images/delaunay.png"/>
    </div>

  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Corentin Dumery</title>

    <meta name="author" content="Corentin Dumery">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon.png" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="images/favicon.png">
    
    <meta property="og:type" content="website">
    <meta property="og:image" content="images/flower.png" />
    <meta property="og:description" content="Personal website and portfolio" />
    <meta property="og:title" content="Corentin Dumery" />
      
    <meta property="twitter:card" content="summary">
    <meta property="twitter:title" content="Corentin Dumery">
    <meta property="twitter:description" content="Personal website and portfolio">
    <meta property="twitter:image" content="images/flower.png">
  </head>    
    

  <body>

    <div class="navbar">
      <a href="index.html" class="current_navbar">Corentin Dumery</a>
      <a href="about/gallery.html">Projects</a>
      <a href="about/gallery.html">Gallery</a>
      <a href="about/blog.html">Blog</a>
    </div>

    <div style="height: 40px;"></div>
  
    <!--
    <div style="height: 5vh; width: 100%; max-width: 1000px; background-color: white; margin: 0 auto;"></div>-->


    <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;padding-top:0.3%;" ><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" bgcolor="#ffffff"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;padding-bottom:1.5%;width:63%;vertical-align:middle;">

                <h1> Corentin Dumery </h1>
                <h3> PhD student
                at&nbsp;
                <img src="images/epfl-black.png" height="16em" alt=" EPFL"/> / Intern at Meta Redmond<br>
                
                <a href="https://www.epfl.ch/labs/cvlab/">CVLab</a>
                </h3>
                <h4> Contact: <br> first name dot last name at epfl dot ch </h4>

                I graduated from <a href="https://www.nus.edu.sg">NUS</a> and
                <a href="https://www.telecom-paris.fr/en/home">Télécom Paris</a> in 2020.
                After graduation, I worked at
                <a href="https://www.cea.fr/english/Pages/cea/the-cea-a-key-player-in-technological-research.aspx">CEA Paris-Saclay</a>
                on polycube mapping, and later joined <a href="https://igl.ethz.ch/people/sorkine/index.php">Prof. Olga Sorkine-Hornung</a>'s
                lab at ETH Zürich as a visiting researcher on garment fabrication. Since 2023, I am supervised by <a href="https://people.epfl.ch/pascal.fua/bio?lang=en">Prof. Pascal Fua</a> at EPFL's CVLab, where I am working on 3D Computer Vision.
                <br/>
                <p>
                For those who are unsure, <a href="sound/corentindumery.mp3">here</a>'s how my name is pronounced in French.
                </p>

              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/circle_cv_photo.PNG"><img style="width:80%;max-width:80%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/circle_cv_photo.PNG" class="hoverZoomLink"></a>
              </td>
            </tr>
            
          </tbody></table>
          <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" bgcolor="#ffffff"><tbody>
              <tr>
              <td style="padding-left:2.5%;padding-right:2.5%;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                    My research interests lie at the intersection of computer vision and computer graphics. 
                    I am dedicated to advancing machine perception through 3D scene reconstruction and understanding, enabling machines to not
                    only see their environment but also comprehend and interact with it. My work also emphasizes 3D content creation for digital
                    AR/VR environments, leveraging both real-world reconstruction and AI-assisted 3D generation.
                    <br/><br/>
                    
                    <span>&#10230;</span> Students interested in a <b>semester project or master thesis</b>, please consult our lab's <a href="https://www.epfl.ch/labs/cvlab/projects/">project page</a>.</br>
                    <span>&#10230;</span> Master/Bachelor <b>summer interns</b>, please apply to the <a href="https://summer.epfl.ch/">Summer@EPFL</a> program.</br>
                    <span>&#10230;</span> <b>PhD applicants</b>, please refer to the <a href="https://www.epfl.ch/education/phd/edic-computer-and-communication-sciences/">doctoral program page</a> or our 
                    <a href="https://epic-guide.github.io/">student-wiki</a>.</br>
                    <span class="half-line"></span>
                    Feel free to contact me! Please make it clear you have had a look at these resourses and avoid sending a generic email.
                </p>

                <iconbar>
                  <a href="https://github.com/CorentinDumery/"><img class="icon" src="images/github.png"></a>
                  <a href="https://www.youtube.com/channel/UCEiDor6J3-FmC9I1Sv-AKtQ"><img class="icon" src="images/youtube.png"></a>
                  <a href="https://www.linkedin.com/in/corentin-dumery-2754281a0/"><img class="icon" src="images/linkedin.png"></a>
                  <a href="https://scholar.google.com/citations?hl=fr&user=lUXqyiMAAAAJ"><img class="icon" src="images/scholar.png"></a>
              </iconbar>
              </td>
            </tr>

            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
    <!-- TEMPLATE:
    <tr class="project-entry" onmouseout="XXX_stop()" onmouseover="XXX_start()">
        <td class="project-thumb">
            <div class="one">
            <div class="two" id='XXX_image'><video  width=100% height=100% muted autoplay loop>
            <source src="images/papers/XXX.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/papers/XXX.png' width="200">
            </div>
            <script type="text/javascript">
            function XXX_start() {
                document.getElementById('XXX_image').style.opacity = "1";
            }
    
            function XXX_stop() {
                document.getElementById('XXX_image').style.opacity = "0";
            }
            XXX_stop()
            </script>
        </td>
        <td class="project-cell">
            <a href="projects/XXX">
            <span class="papertitle">XXX: xxx</span>
            </a>
            <span class="half-line"></span>
            <strong>Corentin Dumery</strong>,
            <a href="...">author</a>,
            <a href="...">author</a>,
            <a href="...">author</a>
            <br>
            Venue YEAR
            <br>

            <span class="half-line"></span>
            | <a href="projects/XXX">Project page</a>
            | <a href="projects/XXX">Paper</a>
            |
            <span class="half-line"></span>
            <short-desc> XXX description
            </short-desc>
        </td>
    </tr>
    -->

    <tr class="project-entry" onmouseout="stacks_stop()" onmouseover="stacks_start()">
        <td class="project-thumb">
            <div class="one">
            <div class="two" id='stacks_image'><video  width=100% height=100% muted autoplay loop>
            <source src="images/papers/stacks.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/papers/stacks.png' width="200">
            </div>
            <script type="text/javascript">
            function stacks_start() {
                document.getElementById('stacks_image').style.opacity = "1";
            }
    
            function stacks_stop() {
                document.getElementById('stacks_image').style.opacity = "0";
            }
            stacks_stop()
            </script>
        </td>
        <td class="project-cell">
            <a href="projects/stacks.html">
            <span class="papertitle">Counting Stacked Objects</span>
            </a>
            <span class="half-line"></span>
            <strong>Corentin Dumery</strong>,
            <a href="https://emien.ch/">Noa Etté</a>,
            <a href="https://aoxiangfan.github.io/">Aoxiang Fan</a>,
            <a href="https://liren2515.github.io/page/">Ren Li</a>,
            <a href="https://jingyixu.net/">Jingyi Xu</a>,
            <a href="https://hieulem.github.io/">Hieu Le</a>,
            <a href="https://people.epfl.ch/pascal.fua/bio?lang=en">Pascal Fua</a>
            <br>
            arXiv 2025
            <br>

            <span class="half-line"></span>
            | <a href="projects/stacks.html">Project page</a>
            | <a href="https://arxiv.org/abs/2411.19149">Paper</a>
            |
            <span class="half-line"></span>
            <short-desc> We predict the total count of stacked objects, including hidden instances, by <b>estimating the volume</b> through 3D reconstruction and the <b>packing density</b> with a neural network. 
            </short-desc>
        </td>
    </tr>

    <tr class="project-entry" onmouseout="dmap_stop()" onmouseover="dmap_start()">
      <td class="project-thumb">
          <div class="one">
          <div class="two" id='dmap_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/papers/dmap.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/papers/dmap.png' width="200">
          </div>
          <script type="text/javascript">
          function dmap_start() {
              document.getElementById('dmap_image').style.opacity = "1";
          }
  
          function dmap_stop() {
              document.getElementById('dmap_image').style.opacity = "0";
          }
          dmap_stop()
          </script>
      </td>
      <td class="project-cell">
          <a href="https://liren2515.github.io/page/dmap/dmap.html">
          <span class="papertitle">Single View Garment Reconstruction Using Diffusion Mapping Via Pattern Coordinates</span>
          </a>
          <span class="half-line"></span>
          <a href="https://liren2515.github.io/page/">Ren Li</a>,
          <a href="https://www.linkedin.com/in/cong-cao-28582722b/">Cong Cao</a>,
          <strong>Corentin Dumery</strong>,
          <a href="https://kasvii.github.io/">Yingxuan You</a>,
          <a href="https://www.hao-li.com/Hao_Li/Hao_Li_-_about_me.html">Hao Li</a>,
          <a href="https://people.epfl.ch/pascal.fua/bio?lang=en">Pascal Fua</a>
          <br>
          SIGGRAPH 2025
          <br>

          <span class="half-line"></span>
          | <a href="https://liren2515.github.io/page/dmap/dmap.html">Project page</a>
          | <a href="https://arxiv.org/abs/2504.08353">Paper</a>
          | <a href="https://github.com/liren2515/DMap">Code</a>
          |
          <span class="half-line"></span>
          <short-desc> Given an image, we first compute a <b>mapping between garment pixels, 3D points, and <i>pattern space</i></b>. Then, we use a <b>diffusion model as a prior on the space of deformed garments</b> in this pattern space to fill the partial observation into a complete garment.
          </short-desc>
      </td>
  </tr>

    <tr class="project-entry" onmouseout="disconerf_stop()" onmouseover="disconerf_start()">
        <td class="project-thumb">
            <div class="one">
            <div class="two" id='disconerf_image'><video  width=100% height=100% muted autoplay loop>
            <source src="images/papers/disconerf.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/papers/disconerf.png' width="200">
            </div>
            <script type="text/javascript">
            function disconerf_start() {
                document.getElementById('disconerf_image').style.opacity = "1";
            }
    
            function disconerf_stop() {
                document.getElementById('disconerf_image').style.opacity = "0";
            }
            disconerf_stop()
            </script>
        </td>
        <td class="project-cell">
            <a href="projects/disconerf.html">
            <span class="papertitle">Enforcing View-Consistency in Class-Agnostic 3D Segmentation Fields</span>
            </a>
            <span class="half-line"></span>
            <strong>Corentin Dumery</strong>,
            <a href="https://aoxiangfan.github.io/">Aoxiang Fan</a>,
            <a href="https://liren2515.github.io/page/">Ren Li</a>,
            <a href="https://ntalabot.github.io/">Nicolas Talabot</a>,
            <a href="https://people.epfl.ch/pascal.fua/bio?lang=en">Pascal Fua</a>
            <br>
            CVPRW 2025, 4th Workshop on Open-World 3D Scene Understanding with Foundation Models
            <br>

            <span class="half-line"></span>
            | <a href="projects/disconerf.html">Project page</a>
            | <a href="https://arxiv.org/abs/2408.09928">Paper</a>
            | <a href="https://opensun3d.github.io/">Workshop website</a>
            | <a href="https://drive.google.com/file/d/1qq8o9axqqxhiVmdxQxuH8GpawV0Bel7Y/view?usp=sharing">Ground-Truth Mip-NeRF360 Segmentations</a>
            |
            <span class="half-line"></span>
            <short-desc> We train a 3D object field along with a radiance field, and show how <b>spatial regularization can help obtain a consistent segmentation</b> from inconsistent 2D signal.
            </short-desc>
        </td>
    </tr>

    <tr class="project-entry" onmouseout="manipulated_stop()" onmouseover="manipulated_start()">
        <td class="project-thumb">
            <div class="one">
            <div class="two" id='manipulated_image'><video  width=100% height=100% muted autoplay loop>
            <source src="images/papers/manipulated.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/papers/manipulated.png' width="200">
            </div>
            <script type="text/javascript">
            function manipulated_start() {
                document.getElementById('manipulated_image').style.opacity = "1";
            }
    
            function manipulated_stop() {
                document.getElementById('manipulated_image').style.opacity = "0";
            }
            manipulated_stop()
            </script>
        </td>
        <td class="project-cell">
            <a href="https://liren2515.github.io/page/folding/folding.html">
            <span class="papertitle">Reconstruction of Manipulated Garment with Guided Deformation Prior</span>
            </a>
            <span class="half-line"></span>
            <a href="https://liren2515.github.io/page/">Ren Li</a>,
            <strong>Corentin Dumery</strong>,
            <a href="https://scholar.google.com/citations?user=XDfK4f8AAAAJ">Zhantao Deng</a>,
            <a href="https://people.epfl.ch/pascal.fua/bio?lang=en">Pascal Fua</a>
            <br>
            NeurIPS 2024
            <br>

            <span class="half-line"></span>
            | <a href="https://liren2515.github.io/page/folding/folding.html">Project page</a>
            | <a href="https://arxiv.org/abs/2405.10934">Paper</a>
            | <a href="https://github.com/liren2515/GarmentFolding">Code</a>
            |
            <span class="half-line"></span>
            <short-desc> From a partial point cloud of a garment being <b>folded or manipulated</b>, we <b>map points to 2D and recover complete patterns</b>, allowing us to retrieve a full garment.
            </short-desc>
        </td>
    </tr>

    <tr class="project-entry" onmouseout="garment_stop()" onmouseover="garment_start()">
        <td class="project-thumb">
            <div class="one">
            <div class="two" id='garment_image'><video  width=100% height=100% muted autoplay loop>
            <source src="images/papers/garment.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/papers/garment.png' width="200">
            </div>
            <script type="text/javascript">
            function garment_start() {
                document.getElementById('garment_image').style.opacity = "1";
            }
    
            function garment_stop() {
                document.getElementById('garment_image').style.opacity = "0";
            }
            garment_stop()
            </script>
        </td>
        <td class="project-cell">
            <a href="https://liren2515.github.io/page/prior/prior.html">
            <span class="papertitle">Garment Recovery with Shape and Deformation Priors</span>
            </a>
            <span class="half-line"></span>
            <a href="https://liren2515.github.io/page/">Ren Li</a>,
            <strong>Corentin Dumery</strong>,
            <a href="https://bguillard.github.io/">Benoit Guillard</a>,
            <a href="https://people.epfl.ch/pascal.fua/bio?lang=en">Pascal Fua</a>
            <br>
            CVPR 2024
            <br>

            <span class="half-line"></span>
            | <a href="https://liren2515.github.io/page/prior/prior.html">Project page</a>
            | <a href="https://arxiv.org/abs/2311.10356">Paper</a>
            | <a href="https://github.com/liren2515/GarmentRecovery">Code</a>
            |
            <span class="half-line"></span>
            <short-desc> We train a model to <b>learn the space of deformed garments</b>, and fit this prior to single view images to recover a complete garment mesh even though only half of it is invisible.
            </short-desc>
        </td>
    </tr>
    
    <tr class="project-entry" onmouseout="evocube_stop()" onmouseover="evocube_start()">
        <td class="project-thumb">
            <div class="one">
            <div class="two" id='evocube_image'><video  width=100% height=100% muted autoplay loop>
            <source src="images/papers/evocube.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/papers/evocube.png' width="200">
            </div>
            <script type="text/javascript">
            function evocube_start() {
                document.getElementById('evocube_image').style.opacity = "1";
            }
    
            function evocube_stop() {
                document.getElementById('evocube_image').style.opacity = "0";
            }
            evocube_stop()
            </script>
        </td>
        <td class="project-cell">
            <a href="projects/evocube.html">
            <span class="papertitle">Evocube: a Genetic Labeling Framework for Polycube-Maps</span>
            </a>
            <span class="half-line"></span>
            <strong>Corentin Dumery</strong>,
            <a href="https://fprotais.github.io/">François Protais</a>,
            <a href="https://sebastienmestrallet.fr/">Sébastien Mestrallet</a>,
            <a href="https://cv.hal.science/cbourcier">Christophe Bourcier</a>,
            <a href="https://www-lihpc.cea.fr/fr/team/permanents/ledoux.html">Franck Ledoux</a>
            <br>
            Computer Graphics Forum (Eurographics) 2023
            <br>

            <span class="half-line"></span>
            | <a href="projects/evocube.html">Project page</a>
            | <a href="https://arxiv.org/abs/2205.00738">Paper</a>
            | <a href="https://github.com/LIHPC-Computational-Geometry/evocube"">Code</a>
            | <a href="https://www.youtube.com/watch?v=vjxIBLl6Td4">Video</a>
            |
            <span class="half-line"></span>
            <short-desc> To morph an arbitrary 3D shape into a <b><i>polycube</i></b>, i.e. an aggregate of axis-aligned cubes, we design a <b>genetic algorithm to produce valid polycube labelings</b> after multiple generations of crossovers and mutations. These polycubes are then used to produce <b>hexahedral meshes</b> for finite-element simulation.
            </short-desc>
        </td>
    </tr>


    <tr class="project-entry" onmouseout="patterns_stop()" onmouseover="patterns_start()">
        <td class="project-thumb">
            <div class="one">
            <div class="two" id='patterns_image'><video  width=100% height=100% muted autoplay loop>
            <source src="images/papers/patterns.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/papers/patterns.png' width="200">
            </div>
            <script type="text/javascript">
            function patterns_start() {
                document.getElementById('patterns_image').style.opacity = "1";
            }
    
            function patterns_stop() {
                document.getElementById('patterns_image').style.opacity = "0";
            }
            patterns_stop()
            </script>
        </td>
        <td class="project-cell">
            <a href="https://igl.ethz.ch/projects/computational-patternmaking/">
            <span class="papertitle">Computational Pattern Making from 3D Garment Models</span>
            </a>
            <span class="half-line"></span>
            <a href="https://www.nicopietroni.com/">Nico Pietroni</a>,
            <strong>Corentin Dumery</strong>,
            <a href="https://profiles.uts.edu.au/raphael.falque">Raphael Falque</a>,
            <a href="https://profiles.uts.edu.au/Teresa.VidalCalleja">Teresa Vidal-Calleja</a>,
            <a href="https://igl.ethz.ch/people/sorkine/">Olga Sorkine-Hornung</a>
            <br>
            SIGGRAPH 2022
            <br>

            <span class="half-line"></span>
            | <a href="https://igl.ethz.ch/projects/computational-patternmaking/">Project page</a>
            | <a href="https://igl.ethz.ch/projects/computational-patternmaking/computational-pattern-making-paper.pdf">Paper (38 Mb)</a>
            | <a href="projects/computational-pattern-making-compressed.pdf">Paper (2 Mb)</a>
            | <a href="https://github.com/CorentinDumery/garment-flattening">Code (Garment Flattening)</a>
            | <a href="https://github.com/nicopietroni/parafashion">Code (Patch Segmentation)</a>
            | <a href="https://www.youtube.com/watch?v=7b27T8rh7SU">Supplemental Video</a>
            | <a href="https://igl.ethz.ch/publications/igl-bibtex.php#ComputationalPatternmaking:2022">bibtex</a>
            |
            <span class="half-line"></span>
            <short-desc> Given a 3D garment, we compute 2D patterns that can be directly manufactured. To this end, we optimize a <b>cross field</b> that generates good cutting lines, and propose a <b>mesh flattening</b> method tailored to woven materials.
            </short-desc>
        </td>
    </tr>


          </tbody></table>

          
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;" bgcolor="#fff"><tbody>
            <tr>
              <td>
                <h2>Other</h2>
                <br>
                <b>Academic Service</b>:
                <ul>
                  <li> <a href="https://cvpr.thecvf.com/Conferences/2025/ProgramCommittee">Outstanding reviewer</a> at CVPR25 (top 5.6%). 
                  <li>Reviewer for major Vision (CVPR, BMVC) and Graphics (SIGGRAPH, CGF, PG) conferences.
                </ul>
                <br>
                <b>Head Teaching Assitant</b> for:
                <ul>
                  <li>CS433 Machine Learning (600 students, 30 teaching assistants) taught by Prof. <a href="https://people.epfl.ch/martin.jaggi">M. Jaggi</a> and <a href="https://people.epfl.ch/nicolas.flammarion">N. Flammarion</a> (2023, 2024)</li>
                  <li>CS442 Computer Vision (200 students, 9 teaching assistants) with Prof. <a href="https://people.epfl.ch/pascal.fua/bio?lang=en">Pascal Fua</a> (2023, 2024)</li>
                </ul>
                <br>           

                <b>Associations</b>:
                <ul>
                  <li>I am the VP/Treasurer of <a href="https://www.epfl.ch/campus/associations/epic/">EPIC</a>, the association of CS PhDs of EPFL.
                </ul>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%; margin:0 auto; margin-top: 10px; border:0; border-spacing:0; padding:16px;" bgcolor="#fff"><tbody>
            <tr>
              <td>
                <h2>Additional Workshop Presentations (no proceedings)</h2>
                <br>
                <strong><a href="https://arxiv.org/abs/2504.07370">View-Dependent Uncertainty Estimation of 3D Gaussian Splatting</a></strong><br>
                Chenyu Han, <strong>Corentin Dumery</strong><br>
                <i>CVPR25 Workshop on Uncertainty Quantification for Computer Vision (UNCV)</i>, Extended Abstract<br>
              </td>
            </tr>
          </tbody></table>

          <!--
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #fcb97d;">
								 <h2>Micropapers</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
              </td>
            </tr>


            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #aaba9e;">
								 <h2>Recorded Talks</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://www.youtube.com/watch?v=hFlF33JZbA0">Radiance Fields and the Future of Generative Media, 2025</a><br>				  
                <a href="https://www.youtube.com/watch?v=h9vq_65eDas">View Dependent Podcast, 2024</a><br>
                <a href="https://www.youtube.com/watch?v=4tDhYsFuEqo">Bay Area Robotics Symposium, 2023
</a><br>
                <a href="https://youtu.be/TvWkwDYtBP4?t=7604">EGSR Keynote, 2021</a><br>
				<a href="https://www.youtube.com/watch?v=nRyOzHpcr4Q">TUM AI Lecture Series, 2020</a><br>
				<a href="https://www.youtube.com/watch?v=HfJpQCBTqZs">Vision & Graphics Seminar at MIT, 2020</a>
              </td>
            </tr>

            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #c6b89e;">
								 <h2>Academic Service</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://iccv.thecvf.com/">Lead Area Chair, ICCV 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2025/Organizers">Lead Area Chair, CVPR 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
                <br>
                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                <br>
                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                <br>
                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>
                <br>
                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                <br>
                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
              </td>
            </tr>
						
						
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #edd892;">
								 <h2>Teaching</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
                <br>
                <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
              </td>
            </tr>
            
          </tbody></table>

          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  A nice message...
                </p>
              </td>
            </tr>
          </tbody></table>-->
        </td>
      </tr>
    </table>

  </body>
</html>
