<!DOCTYPE html>
<html>

<head>
  <title>Corentin Dumery</title>
  <link rel="stylesheet" href="../style.css" />
  <link rel="stylesheet" href="project.css" />
</head>


<header>
  <img id="header_background" src="../images/delaunay.png"/>
</header>

<body>
  <!--
  <menubar>
    <a href="../index.html"><moving>Corentin Dumery</moving></a>
    <a href="../about/resume.html"> <moving> Resume  </moving> </a>
    <a href="../about/gallery.html"> <moving> Gallery </moving> </a>
    <a href="../about/blog.html"> <moving> Blog </moving></a>
  </menubar>
-->

  <article>
    <div class="article_text">

      <a href="../index.html"> <backbutton> <i> ‚Üê Back to my website </i></backbutton></a>

      <paper-title> Enforcing View-Consistency in Class-Agnostic 3D Segmentation Fields </paper-title>
      <paper-published> CVPRW 2025<br><a href='https://opensun3d.github.io/'> (4th Workshop on Open-World 3D Scene Understanding with Foundation Models)</a> </paper-published>

      <div class="horizontal-bar">
        <a class="horizontal-bar-item" href="https://arxiv.org/abs/2408.09928">
          <img class="icon" src="../images/paper.png">
          <p>Paper</p>
        </a>
        <a class="horizontal-bar-item" href="https://drive.google.com/file/d/1qq8o9axqqxhiVmdxQxuH8GpawV0Bel7Y/view?usp=sharing">
          <img class="icon" src="../images/dataset.png">
          <p>Mip-NeRF360 </br>Ground-Truth Segmentations</p>
        </a>
      </div>

      <paper-teaser><img src="../images/disconerf.png"></paper-teaser>

      <div style="width: 75%; margin: auto;"><b><i>Given as input a set of class-agnostic 2D masks with little consistency across views, we aim to
      learn a meaningful 3D object field that segments the different instances in the scene. The discovered objects can then be extracted and
      rendered independently.</i></b></div><br>

      <paper-section> Abstract </paper-section>
      Radiance Fields have become a powerful tool for modeling 3D scenes from multiple images. However, they remain difficult to segment into semantically meaningful regions. 
      Some methods work well using 2D semantic masks, but they <b>generalize poorly to class-agnostic segmentations</b>. More recent methods circumvent this issue by using contrastive learning to optimize a high-dimensional 3D feature field instead. However, recovering a segmentation then requires clustering and fine-tuning the associated hyperparameters.
      In contrast, we aim to <b>identify the necessary changes in segmentation field methods to directly learn a segmentation field while being robust to inconsistent class-agnostic masks</b>, successfully decomposing the scene into a set of objects of any class.
      </br>
      By introducing an additional <b>spatial regularization term</b> and restricting the field to <b>a limited number of competing object slots against which masks are matched</b>, a meaningful object representation emerges that best explains the 2D supervision.
      Our experiments demonstrate the ability of our method to generate 3D panoptic segmentations on complex scenes, and extract high-quality 3D assets from radiance fields that can then be used in virtual 3D environments.

      <br><br>
      <paper-section> Citation </paper-section>
      <bibtex>
      @article{dumery25enforcing,<br>
        <bibtex-body>
        &nbsp;&nbsp;    title = {{Enforcing View-Consistency in Class-Agnostic 3D Segmentation Fields}},<br>
        &nbsp;&nbsp;    author = {Dumery, Corentin and Fan, Aoxiang and Li, Ren and Talabot, Nicolas and Fua, Pascal},<br>
        &nbsp;&nbsp;    journal = {{CVPRW}},<br>
        &nbsp;&nbsp;    year = {2025},<br>
        </bibtex-body>
      }
      </bibtex>
    </div>
  </article>

</body>

</html>
